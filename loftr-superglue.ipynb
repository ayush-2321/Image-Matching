{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c2ea76",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-29T14:42:17.353085Z",
     "iopub.status.busy": "2023-04-29T14:42:17.352617Z",
     "iopub.status.idle": "2023-04-29T14:42:17.364968Z",
     "shell.execute_reply": "2023-04-29T14:42:17.362739Z"
    },
    "papermill": {
     "duration": 0.022481,
     "end_time": "2023-04-29T14:42:17.368449",
     "exception": false,
     "start_time": "2023-04-29T14:42:17.345968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab1ae9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:42:17.385670Z",
     "iopub.status.busy": "2023-04-29T14:42:17.385252Z",
     "iopub.status.idle": "2023-04-29T14:42:19.812995Z",
     "shell.execute_reply": "2023-04-29T14:42:19.811968Z"
    },
    "papermill": {
     "duration": 2.438246,
     "end_time": "2023-04-29T14:42:19.815352",
     "exception": false,
     "start_time": "2023-04-29T14:42:17.377106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "\n",
    "# import sys\n",
    "# # sys.path.append(\"../input/super-glue-pretrained-network\")\n",
    "# # from models.matching import Matching\n",
    "# # from models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "# #                           estimate_pose, make_matching_plot,\n",
    "# #                           error_colormap, AverageTimer, pose_auc, read_image,\n",
    "# #                           rotate_intrinsics, rotate_pose_inplane,\n",
    "# #                           scale_intrinsics)\n",
    "from os import listdir\n",
    "# import kornia as K\n",
    "# import kornia.feature as KF\n",
    "# import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a50cae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:42:19.825477Z",
     "iopub.status.busy": "2023-04-29T14:42:19.823819Z",
     "iopub.status.idle": "2023-04-29T14:42:19.894917Z",
     "shell.execute_reply": "2023-04-29T14:42:19.893798Z"
    },
    "papermill": {
     "duration": 0.077925,
     "end_time": "2023-04-29T14:42:19.897169",
     "exception": false,
     "start_time": "2023-04-29T14:42:19.819244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9201f",
   "metadata": {
    "papermill": {
     "duration": 0.003793,
     "end_time": "2023-04-29T14:42:19.904725",
     "exception": false,
     "start_time": "2023-04-29T14:42:19.900932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing LOFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d9c91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:42:19.913325Z",
     "iopub.status.busy": "2023-04-29T14:42:19.913011Z",
     "iopub.status.idle": "2023-04-29T14:43:21.409815Z",
     "shell.execute_reply": "2023-04-29T14:43:21.408611Z"
    },
    "papermill": {
     "duration": 61.504166,
     "end_time": "2023-04-29T14:43:21.412474",
     "exception": false,
     "start_time": "2023-04-29T14:42:19.908308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (1.13.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (23.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.8.1->kornia==0.6.4) (4.4.0)\r\n",
      "Installing collected packages: kornia\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.6.11\r\n",
      "    Uninstalling kornia-0.6.11:\r\n",
      "      Successfully uninstalled kornia-0.6.11\r\n",
      "Successfully installed kornia-0.6.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (3.5.3)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (1.13.0)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (4.5.4.60)\r\n",
      "Requirement already satisfied: kornia in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (0.6.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia->kornia-moons==0.1.9) (23.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->kornia-moons==0.1.9) (4.4.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.4.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (0.11.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (9.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (2.8.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (4.38.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.21.6)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->kornia-moons==0.1.9) (1.16.0)\r\n",
      "Installing collected packages: kornia-moons\r\n",
      "Successfully installed kornia-moons-0.1.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "dry_run = False\n",
    "!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n",
    "!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985ba45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:21.423293Z",
     "iopub.status.busy": "2023-04-29T14:43:21.422960Z",
     "iopub.status.idle": "2023-04-29T14:43:22.933872Z",
     "shell.execute_reply": "2023-04-29T14:43:22.932566Z"
    },
    "papermill": {
     "duration": 1.519247,
     "end_time": "2023-04-29T14:43:22.936501",
     "exception": false,
     "start_time": "2023-04-29T14:43:21.417254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "from glob import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia\n",
    "from kornia_moons.feature import *\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c5988f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:22.947273Z",
     "iopub.status.busy": "2023-04-29T14:43:22.946955Z",
     "iopub.status.idle": "2023-04-29T14:43:27.348122Z",
     "shell.execute_reply": "2023-04-29T14:43:27.347017Z"
    },
    "papermill": {
     "duration": 4.409506,
     "end_time": "2023-04-29T14:43:27.350916",
     "exception": false,
     "start_time": "2023-04-29T14:43:22.941410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "matcher = KF.LoFTR(pretrained=None)\n",
    "matcher.load_state_dict(torch.load(\"../input/kornia-loftr/loftr_outdoor.ckpt\")['state_dict'])\n",
    "matcher = matcher.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba638e4",
   "metadata": {
    "papermill": {
     "duration": 0.004364,
     "end_time": "2023-04-29T14:43:27.360373",
     "exception": false,
     "start_time": "2023-04-29T14:43:27.356009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing Super Glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c9ed3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:27.370556Z",
     "iopub.status.busy": "2023-04-29T14:43:27.370192Z",
     "iopub.status.idle": "2023-04-29T14:43:27.422447Z",
     "shell.execute_reply": "2023-04-29T14:43:27.421408Z"
    },
    "papermill": {
     "duration": 0.060699,
     "end_time": "2023-04-29T14:43:27.425466",
     "exception": false,
     "start_time": "2023-04-29T14:43:27.364767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/super-glue-pretrained-network\")\n",
    "from models.matching import Matching\n",
    "from models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "                          estimate_pose, make_matching_plot,\n",
    "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
    "                          rotate_intrinsics, rotate_pose_inplane,\n",
    "                          scale_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc21cccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:27.436052Z",
     "iopub.status.busy": "2023-04-29T14:43:27.435728Z",
     "iopub.status.idle": "2023-04-29T14:43:28.486911Z",
     "shell.execute_reply": "2023-04-29T14:43:28.485889Z"
    },
    "papermill": {
     "duration": 1.058898,
     "end_time": "2023-04-29T14:43:28.489119",
     "exception": false,
     "start_time": "2023-04-29T14:43:27.430221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "resize = [-1, ]\n",
    "resize_float = True\n",
    "\n",
    "config = {\n",
    "    \"superpoint\": {\n",
    "        \"nms_radius\": 3,\n",
    "        \"keypoint_threshold\": 0.005,\n",
    "        \"max_keypoints\": 2048\n",
    "    },\n",
    "    \"superglue\": {\n",
    "        \"weights\": \"outdoor\",\n",
    "        \"sinkhorn_iterations\": 100,\n",
    "        \"match_threshold\": 0.2,\n",
    "    }\n",
    "}\n",
    "matching = Matching(config).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d5f2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:28.500274Z",
     "iopub.status.busy": "2023-04-29T14:43:28.499321Z",
     "iopub.status.idle": "2023-04-29T14:43:28.513085Z",
     "shell.execute_reply": "2023-04-29T14:43:28.512120Z"
    },
    "papermill": {
     "duration": 0.021355,
     "end_time": "2023-04-29T14:43:28.515086",
     "exception": false,
     "start_time": "2023-04-29T14:43:28.493731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = '/kaggle/input/image-matching-challenge-2022/'\n",
    "\n",
    "test_samples = []\n",
    "with open(f'{src}/test.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        test_samples += [row]\n",
    "\n",
    "\n",
    "def FlattenMatrix(M, num_digits=8):\n",
    "    '''Convenience function to write CSV files.'''\n",
    "    \n",
    "    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n",
    "\n",
    "\n",
    "def load_torch_image(fname, device):\n",
    "    img = cv2.imread(fname)\n",
    "    scale = 840 / max(img.shape[0], img.shape[1]) \n",
    "    w = int(img.shape[1] * scale)\n",
    "    h = int(img.shape[0] * scale)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img = K.image_to_tensor(img, False).float() /255.\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    return img.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c1514",
   "metadata": {
    "papermill": {
     "duration": 0.004337,
     "end_time": "2023-04-29T14:43:28.525485",
     "exception": false,
     "start_time": "2023-04-29T14:43:28.521148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e048de30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:28.537180Z",
     "iopub.status.busy": "2023-04-29T14:43:28.535615Z",
     "iopub.status.idle": "2023-04-29T14:43:29.827088Z",
     "shell.execute_reply": "2023-04-29T14:43:29.826040Z"
    },
    "papermill": {
     "duration": 1.299651,
     "end_time": "2023-04-29T14:43:29.829597",
     "exception": false,
     "start_time": "2023-04-29T14:43:28.529946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_resized_image(fname, resize): # function t read an image at a particular scale(when filename is given)\n",
    "    img = cv2.imread(fname)\n",
    "    h, w, _ = img.shape\n",
    "    scale = resize / max(h, w) \n",
    "    w = int(w * scale)\n",
    "    h = int(h * scale)\n",
    "    \n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = torch.from_numpy(img)[None][None]/ 255.\n",
    "    \n",
    "    return img.to(device), scale\n",
    "\n",
    "def load_image1(fname):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = K.image_to_tensor(img, False).float() /255.\n",
    "    return img.to(device)\n",
    "\n",
    "def load_resized_image1(img, resize): # function t read an image at a particular scale(when image itself is given)\n",
    "    img=img[0,0,:,:]\n",
    "    h, w = img.shape\n",
    "    img=img.cpu().numpy()\n",
    "    scale = resize / max(h, w) \n",
    "    w_new = int(w * scale)\n",
    "    h_new = int(h * scale)\n",
    "    \n",
    "    img = cv2.resize(img, (w_new, h_new))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = torch.from_numpy(img)[None][None]\n",
    "    \n",
    "    return img.to(device), [h_new/h,w_new/w]\n",
    "\n",
    "def scale_to_resized(mkpts0, mkpts1, scale1,scale2):\n",
    "    ### scale to original im size because we used max_image_size\n",
    "    # first point\n",
    "    mkpts0[:, 0] = mkpts0[:, 0] / scale1[0]\n",
    "    mkpts0[:, 1] = mkpts0[:, 1] / scale1[1]    \n",
    "    # second point\n",
    "    mkpts1[:, 0] = mkpts1[:, 0] / scale2[0]\n",
    "    mkpts1[:, 1] = mkpts1[:, 1] / scale2[1]\n",
    "    \n",
    "    return mkpts0, mkpts1\n",
    "\n",
    "\n",
    "def get_loftr_match(img1,img2):\n",
    "    input_dict = {\"image0\": (img1), \n",
    "              \"image1\": (img2)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correspondences = matcher(input_dict)\n",
    "        \n",
    "    a1 = correspondences['keypoints0'].cpu().numpy()\n",
    "    a2 = correspondences['keypoints1'].cpu().numpy()\n",
    "    return a1,a2\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def crop_image(image, matching_points, eps, min_samples=5):\n",
    "    # Convert matching points to numpy array\n",
    "    matching_points = np.array(matching_points)\n",
    "\n",
    "    # Apply DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(matching_points)\n",
    "\n",
    "    # Find the most dense cluster\n",
    "    unique_labels, label_counts = np.unique(clustering.labels_, return_counts=True)\n",
    "#     print(unique_labels)\n",
    "#     print(label_counts)\n",
    "    most_dense_cluster_label = unique_labels[np.argmax(label_counts)]\n",
    "#     print(unique_labels)\n",
    "    # Get the matching points in the most dense cluster\n",
    "    cluster_points = matching_points[clustering.labels_ == most_dense_cluster_label]\n",
    "#     print(cluster_points)\n",
    "    # Calculate the minimum and maximum coordinates in the cluster\n",
    "    min_x = int(np.min(cluster_points[:, 0]))\n",
    "    max_x = int(np.max(cluster_points[:, 0]))\n",
    "    min_y = int(np.min(cluster_points[:, 1]))\n",
    "    max_y = int(np.max(cluster_points[:, 1]))\n",
    "    # Crop the image based on the cluster coordinates\n",
    "    cropped_image = image[0,0,int(min_y):int(max_y), int(min_x):int(max_x)]\n",
    "\n",
    "    return cropped_image,min_x,min_y\n",
    "\n",
    "def get_superglue(img1,img2):\n",
    "    pred = matching({\"image0\": img1, \"image1\": img2})\n",
    "    pred = {k: v[0].detach().cpu().numpy() for k, v in pred.items()}\n",
    "    # nd1 = time.time()\n",
    "    kpts1, kpts2 = pred[\"keypoints0\"], pred[\"keypoints1\"]\n",
    "    matches, conf = pred[\"matches0\"], pred[\"matching_scores0\"]\n",
    "\n",
    "    valid = matches > -1\n",
    "    a1 = kpts1[valid]\n",
    "    a2 = kpts2[matches[valid]]\n",
    "    mconf = conf[valid]\n",
    "    return a1,a2\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68852a",
   "metadata": {
    "papermill": {
     "duration": 0.004227,
     "end_time": "2023-04-29T14:43:29.838665",
     "exception": false,
     "start_time": "2023-04-29T14:43:29.834438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98960d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T14:43:29.849405Z",
     "iopub.status.busy": "2023-04-29T14:43:29.849065Z",
     "iopub.status.idle": "2023-04-29T14:43:44.550213Z",
     "shell.execute_reply": "2023-04-29T14:43:44.549113Z"
    },
    "papermill": {
     "duration": 14.709955,
     "end_time": "2023-04-29T14:43:44.553024",
     "exception": false,
     "start_time": "2023-04-29T14:43:29.843069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time:  5.669443845748901  s\n",
      "Running time:  1.1662216186523438  s\n",
      "Running time:  0.9997663497924805  s\n"
     ]
    }
   ],
   "source": [
    "F_dict = {}\n",
    "import time\n",
    "for i, row in enumerate(test_samples):\n",
    "    sample_id, batch_id, image_1_id, image_2_id = row\n",
    "    # Load the images. # sizes of 840,1040,1280\n",
    "    st = time.time()\n",
    "    img11=load_image1(f'{src}/test_images/{batch_id}/{image_1_id}.png')\n",
    "    img22 =load_image1(f'{src}/test_images/{batch_id}/{image_2_id}.png')\n",
    "    img1,scale1 = load_resized_image1(img11, 840)\n",
    "    img2,scale2 = load_resized_image1(img22, 840)\n",
    "    mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts1=mkpts11\n",
    "    mkpts2=mkpts22\n",
    "    \n",
    "#     img1,scale1 = load_resized_image1(img11, 840)\n",
    "#     img2,scale2 = load_resized_image1(img22, 840)\n",
    "#     mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "#     mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "#     mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "#     mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "\n",
    "    \n",
    "    img1,scale1 = load_resized_image1(img11, 1040)\n",
    "    img2,scale2 = load_resized_image1(img22, 1040)\n",
    "    mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "    mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "\n",
    "    img1,scale1 = load_resized_image1(img11, 1240)\n",
    "    img2,scale2 = load_resized_image1(img22, 1240)\n",
    "    mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "    mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "    \n",
    "    \n",
    "    c1,minx1,miny1=crop_image(img11, mkpts1, 20, min_samples=5)\n",
    "    c2,minx2,miny2=crop_image(img22, mkpts2, 20, min_samples=5)\n",
    "    c1=c1.reshape(1,1,c1.shape[0],c1.shape[1])\n",
    "    c2=c2.reshape(1,1,c2.shape[0],c2.shape[1])\n",
    "\n",
    "    img1,scale1=load_resized_image1(c1,840)\n",
    "    img2,scale2=load_resized_image1(c2,840)\n",
    "    mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts11+=np.array([minx1,miny1])\n",
    "    mkpts22+=np.array([minx2,miny2])\n",
    "    mkpts1=mkpts11\n",
    "    mkpts2=mkpts22\n",
    "    \n",
    "#     img1,scale1=load_resized_image1(c1,840)\n",
    "#     img2,scale2=load_resized_image1(c2,840)\n",
    "#     mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "#     mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "#     mkpts11+=np.array([minx1,miny1])\n",
    "#     mkpts22+=np.array([minx2,miny2])\n",
    "#     mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "#     mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "    \n",
    "    img1,scale1=load_resized_image1(c1,1040)\n",
    "    img2,scale2=load_resized_image1(c2,1040)\n",
    "    mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts11+=np.array([minx1,miny1])\n",
    "    mkpts22+=np.array([minx2,miny2])\n",
    "    mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "    mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "    \n",
    "    img1,scale1=load_resized_image1(c1,1280)\n",
    "    img2,scale2=load_resized_image1(c2,1280)\n",
    "    mkpts11,mkpts22=get_superglue(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts11+=np.array([minx1,miny1])\n",
    "    mkpts22+=np.array([minx2,miny2])\n",
    "    mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "    mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "    \n",
    "    \n",
    "    img1,scale1 = load_resized_image1(img11, 840)\n",
    "    img2,scale2 = load_resized_image1(img22, 840)\n",
    "    mkpts11,mkpts22=get_loftr_match(img1,img2)\n",
    "    mkpts11,mkpts22=scale_to_resized(mkpts11, mkpts22, scale1,scale2)\n",
    "    mkpts1=np.vstack((mkpts1,mkpts11))\n",
    "    mkpts2=np.vstack((mkpts2,mkpts22))\n",
    "\n",
    "#     img1=load_image1(f'{src}/test_images/{batch_id}/{image_1_id}.png')\n",
    "#     img2=load_image1(f'{src}/test_images/{batch_id}/{image_2_id}.png')\n",
    "    img1=img11\n",
    "    img2=img22\n",
    "    \n",
    "\n",
    "    \n",
    "    if len(mkpts1) > 7:\n",
    "        F, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 0.25, 0.9999, 10000)\n",
    "#         F, inlier_mask = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, ransacReprojThreshold=0.25, confidence=0.99999, maxIters=10000)\n",
    "        inliers = inliers > 0\n",
    "        assert F.shape == (3, 3), 'Malformed F?'\n",
    "        F_dict[sample_id] = F\n",
    "    else:\n",
    "        F_dict[sample_id] = np.zeros((3, 3))\n",
    "        continue\n",
    "    \n",
    "    nd = time.time() \n",
    "    print(\"Running time: \", nd - st, \" s\")\n",
    "    if (i < 3):\n",
    "#         print(\"Running time: \", nd - st, \" s\")\n",
    "        gc.collect()\n",
    "        draw_LAF_matches(\n",
    "        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n",
    "                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n",
    "                                    torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts2).view(1,-1, 2),\n",
    "                                    torch.ones(mkpts2.shape[0]).view(1,-1, 1, 1),\n",
    "                                    torch.ones(mkpts2.shape[0]).view(1,-1, 1)),\n",
    "        torch.arange(mkpts1.shape[0]).view(-1,1).repeat(1,2),\n",
    "        K.tensor_to_image(img1),\n",
    "        K.tensor_to_image(img2),\n",
    "        inliers,\n",
    "        draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "                   'tentative_color': None, \n",
    "                   'feature_color': (0.2, 0.5, 1), 'vertical': False})\n",
    "       \n",
    "    \n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('sample_id,fundamental_matrix\\n')\n",
    "    for sample_id, F in F_dict.items():\n",
    "        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe7ef3",
   "metadata": {
    "papermill": {
     "duration": 0.004667,
     "end_time": "2023-04-29T14:43:44.563779",
     "exception": false,
     "start_time": "2023-04-29T14:43:44.559112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 98.478288,
   "end_time": "2023-04-29T14:43:47.087742",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-29T14:42:08.609454",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
